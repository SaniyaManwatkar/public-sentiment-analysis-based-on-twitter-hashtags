{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Smruti_Ranjan.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 1**"
      ],
      "metadata": {
        "id": "7GlGIVnTb_o1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vaderSentiment"
      ],
      "metadata": {
        "id": "hM-97W-e6pBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing The Libraries**"
      ],
      "metadata": {
        "id": "G6xuuzRtbb0u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8oOEYQmavJL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import io\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3qCPttle3y2",
        "outputId": "9ee12938-4bcd-4854-b8a5-474450fb4576"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reading the Dataset**"
      ],
      "metadata": {
        "id": "CTVzLGVKcwM6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/dataset.csv',encoding = \"ISO-8859-1\")\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "fH61ds4rfexW",
        "outputId": "7a1f3208-d512-4a9d-965d-164686b5f911"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Data</th>\n",
              "      <th>Date</th>\n",
              "      <th>Time</th>\n",
              "      <th>tweetcaption</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tuesdayvibes</td>\n",
              "      <td>7/14/2020</td>\n",
              "      <td>7:00:21</td>\n",
              "      <td>Love it here vacation vibes amazing beautiful ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>realmeC11</td>\n",
              "      <td>7/14/2020</td>\n",
              "      <td>7:00:21</td>\n",
              "      <td>Best Camera Smartphone under 20k Please vote a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>KPSharmaOli</td>\n",
              "      <td>7/14/2020</td>\n",
              "      <td>7:00:21</td>\n",
              "      <td>shree Why should we have a problem with the pe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RheaChakraborty</td>\n",
              "      <td>7/14/2020</td>\n",
              "      <td>7:00:21</td>\n",
              "      <td>Rhea Chakraborty s Heartbreaking Post On Susha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Stop_Transfer_Sunita_Yadav</td>\n",
              "      <td>7/14/2020</td>\n",
              "      <td>7:00:21</td>\n",
              "      <td>We stand for Sunita Yadav Stop the Transfer Wh...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          Data  ...                                       tweetcaption\n",
              "0                 tuesdayvibes  ...  Love it here vacation vibes amazing beautiful ...\n",
              "1                    realmeC11  ...  Best Camera Smartphone under 20k Please vote a...\n",
              "2                  KPSharmaOli  ...  shree Why should we have a problem with the pe...\n",
              "3              RheaChakraborty  ...  Rhea Chakraborty s Heartbreaking Post On Susha...\n",
              "4   Stop_Transfer_Sunita_Yadav  ...  We stand for Sunita Yadav Stop the Transfer Wh...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cleaning the DATA**"
      ],
      "metadata": {
        "id": "PpWj31Exc79R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Tweets = data[\"tweetcaption\"]\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "#Cleaning tweet function\n",
        "def cleaning(sentence):\n",
        "    sentence = re.sub('[^a-zA-Z]',' ',sentence)            #removing everything except the characters\n",
        "    words = sentence.split()\n",
        "\n",
        "    #Lemmatizing the words\n",
        "    words = [lemmatizer.lemmatize(word) for word in  words if not word in stopwords.words('english')]\n",
        "    sentence = ' '.join(words)\n",
        "    return sentence\n",
        "\n",
        "for i in range(len(Tweets)):\n",
        "    Tweets[i] = cleaning(Tweets[i])\n",
        "    "
      ],
      "metadata": {
        "id": "FeD2PYnPfzsG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Using Vader to make the Scoring**"
      ],
      "metadata": {
        "id": "kmcohjGad2A3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos = []\n",
        "neg = []\n",
        "neu = []\n",
        "compound = []\n",
        "\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "#making the scores for each tweet\n",
        "for i in range(len(Tweets)):\n",
        "    scores = analyzer.polarity_scores(Tweets[i])\n",
        "    pos.append(scores[\"pos\"])\n",
        "    neg.append(scores[\"neg\"])\n",
        "    neu.append(scores[\"neu\"])\n",
        "    compound.append(scores[\"compound\"])\n",
        "\n",
        "data[\"Compound Score\"] = compound\n",
        "data[\"Positivity\"] = pos\n",
        "data[\"Negativity\"] = neg\n",
        "data[\"Neutrality\"] = neu\n",
        "\n",
        "data.head()"
      ],
      "metadata": {
        "id": "r44ZUx-PkX2l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "6a398e5c-d037-44c4-d0f6-2a98ffbc7a74"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Data</th>\n",
              "      <th>Date</th>\n",
              "      <th>Time</th>\n",
              "      <th>tweetcaption</th>\n",
              "      <th>Compound Score</th>\n",
              "      <th>Positivity</th>\n",
              "      <th>Negativity</th>\n",
              "      <th>Neutrality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tuesdayvibes</td>\n",
              "      <td>7/14/2020</td>\n",
              "      <td>7:00:21</td>\n",
              "      <td>Love vacation vibe amazing beautiful cabo mexi...</td>\n",
              "      <td>0.9790</td>\n",
              "      <td>0.191</td>\n",
              "      <td>0.054</td>\n",
              "      <td>0.755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>realmeC11</td>\n",
              "      <td>7/14/2020</td>\n",
              "      <td>7:00:21</td>\n",
              "      <td>Best Camera Smartphone k Please vote help reac...</td>\n",
              "      <td>0.9313</td>\n",
              "      <td>0.134</td>\n",
              "      <td>0.031</td>\n",
              "      <td>0.835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>KPSharmaOli</td>\n",
              "      <td>7/14/2020</td>\n",
              "      <td>7:00:21</td>\n",
              "      <td>shree Why problem people We problem Stupid Com...</td>\n",
              "      <td>0.5429</td>\n",
              "      <td>0.128</td>\n",
              "      <td>0.099</td>\n",
              "      <td>0.773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RheaChakraborty</td>\n",
              "      <td>7/14/2020</td>\n",
              "      <td>7:00:21</td>\n",
              "      <td>Rhea Chakraborty Heartbreaking Post On Sushant...</td>\n",
              "      <td>0.9259</td>\n",
              "      <td>0.196</td>\n",
              "      <td>0.130</td>\n",
              "      <td>0.675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Stop_Transfer_Sunita_Yadav</td>\n",
              "      <td>7/14/2020</td>\n",
              "      <td>7:00:21</td>\n",
              "      <td>We stand Sunita Yadav Stop Transfer Where woma...</td>\n",
              "      <td>0.1779</td>\n",
              "      <td>0.188</td>\n",
              "      <td>0.199</td>\n",
              "      <td>0.613</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          Data       Date  ... Negativity Neutrality\n",
              "0                 tuesdayvibes  7/14/2020  ...      0.054      0.755\n",
              "1                    realmeC11  7/14/2020  ...      0.031      0.835\n",
              "2                  KPSharmaOli  7/14/2020  ...      0.099      0.773\n",
              "3              RheaChakraborty  7/14/2020  ...      0.130      0.675\n",
              "4   Stop_Transfer_Sunita_Yadav  7/14/2020  ...      0.199      0.613\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Day wise Scoring***"
      ],
      "metadata": {
        "id": "KRRWSYJgrSpC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Fixing the missing dates in the dataset**"
      ],
      "metadata": {
        "id": "yGIRXnhqTfpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Since a lot of dates are missing ,i.e. only ###### are present on some dates\n",
        "#Assuming the tweets are taken from all the days of the given 3 months\n",
        "#A new date is assigned whenever time goes past 12 AM \n",
        "\n",
        "date = data[\"Date\"]\n",
        "time = data[\"Time\"]\n",
        "\n",
        "for i in range(len(date)):\n",
        "    current_date = date[i]\n",
        "    current_time = time[i]\n",
        "\n",
        "    #Slash found means date is there in the dataset\n",
        "    if(current_date[1] == '/'):\n",
        "        continue\n",
        "    \n",
        "    #else there hash tags in the date column\n",
        "    else:\n",
        "        prev_time = time[i-1]         \n",
        "        prev_month = date[i-1][0]                            #stores the month number of previous data \n",
        "        prev_day = date[i-1][2:4]                            #stores the date number of previous data\n",
        "        if(current_time[0] == '0' and prev_time == '23' ):   #this means time has passed 12AM , therefore changing the date\n",
        "            if(prev_day == \"31\"):                            #if prev_day = 31, means a change of month is required\n",
        "                month = int(prev_month)+1\n",
        "                date[i] = \"{}/01/2020\".format(month)         # 1st date of the next month is assigned\n",
        "\n",
        "            else:\n",
        "                month = int(prev_month)                      \n",
        "                day = int(prev_day) + 1                      # only the day number is changed and month remains same\n",
        "                date[i] = \"{}/{}/2020\".format(month,day)     \n",
        "\n",
        "data[\"Date\"] = date                                          # changing the \"Date\" Column with the updated dates\n",
        "\n",
        "data.to_csv(\"/content/drive/MyDrive/Colab Notebooks/dataset_modified.csv\",encoding = \"ISO-8859-1\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "28bMfZdD9wS2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Making Day-Wise Average Scores**"
      ],
      "metadata": {
        "id": "I-9NONylfIQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "date = data[\"Date\"]\n",
        "\n",
        "#Initializing the variables\n",
        "n = 1\n",
        "new_date = []\n",
        "day_pos = []\n",
        "day_neg = []\n",
        "day_neu = []\n",
        "day_compound = []\n",
        "temp_pos = pos[0]\n",
        "temp_neg = neg[0]\n",
        "temp_neu = neu[0]\n",
        "temp_compound = compound[0]\n",
        "new_date.append(date[0])"
      ],
      "metadata": {
        "id": "cOkNVA9fqKFG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for i in range(1,len(date)):\n",
        "\n",
        "    #for same date, add all the scores\n",
        "    if(date[i] == date[i-1]):\n",
        "        n = n+1                                         # keeps a count of the number of hashtags in a day\n",
        "        temp_pos = temp_pos + pos[i]\n",
        "        temp_neg = temp_neg + neg[i]\n",
        "        temp_neu = temp_neu + neu[i]\n",
        "        temp_compound = temp_compound + compound[i]\n",
        "\n",
        "    else:\n",
        "        #assigning the average scores of a day \n",
        "        day_pos.append(temp_pos/n)\n",
        "        day_neg.append(temp_neg/n)\n",
        "        day_neu.append(temp_neu/n)\n",
        "        day_compound.append(temp_compound/n)\n",
        "        \n",
        "        #re-initializing the temporary variables\n",
        "        temp_pos = pos[i]\n",
        "        temp_neg = neg[i]\n",
        "        temp_neu = neu[i]\n",
        "        temp_compound = compound[i]\n",
        "        n = 1\n",
        "        new_date.append(date[i])\n",
        "\n",
        "#the last date would have not been appended due to the boundary conditions\n",
        "#so appending the last date average scores outside the loop\n",
        "day_pos.append(temp_pos/n)\n",
        "day_neg.append(temp_neg/n)\n",
        "day_neu.append(temp_neu/n)\n",
        "day_compound.append(temp_compound/n)\n",
        "\n",
        "#Creating a dataframe of the day_wise_scores\n",
        "df = {\"Date\":new_date, \n",
        "      \"Compound Score\":day_compound,\n",
        "      \"Positivity\":day_pos,\n",
        "      \"Negativity\":day_neg,\n",
        "      \"Neutrality\":day_neu}\n",
        "\n",
        "day_wise_data = pd.DataFrame(df)\n",
        "\n",
        "print(day_wise_data.shape)\n",
        "print(day_wise_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncGc83ghUXgq",
        "outputId": "832c4d60-f1f1-4720-db81-3c98cb30e1c8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(56, 5)\n",
            "         Date  Compound Score  Positivity  Negativity  Neutrality\n",
            "0   7/14/2020        0.516471    0.191511    0.089447    0.719025\n",
            "1   7/15/2020        0.563632    0.189055    0.079768    0.731176\n",
            "2   7/16/2020        0.512249    0.196261    0.081423    0.722308\n",
            "3   7/17/2020        0.533501    0.203100    0.082841    0.714035\n",
            "4   7/18/2020        0.705279    0.208717    0.070612    0.720645\n",
            "5   7/19/2020        0.546228    0.207766    0.086291    0.705926\n",
            "6   7/20/2020        0.567151    0.211255    0.082932    0.705839\n",
            "7   7/21/2020        0.388422    0.179284    0.100251    0.720498\n",
            "8   7/22/2020        0.600390    0.211059    0.078552    0.710315\n",
            "9   7/23/2020        0.673989    0.216112    0.071441    0.712408\n",
            "10  7/24/2020        0.546054    0.211937    0.083701    0.704482\n",
            "11  7/25/2020        0.588452    0.209074    0.081371    0.709559\n",
            "12  7/26/2020        0.612271    0.206854    0.081801    0.711258\n",
            "13  7/27/2020        0.709165    0.210640    0.071154    0.718209\n",
            "14  7/28/2020        0.551233    0.201457    0.071143    0.727380\n",
            "15  7/29/2020        0.612034    0.209341    0.071803    0.718875\n",
            "16  7/30/2020        0.612932    0.218686    0.065587    0.715760\n",
            "17  7/31/2020        0.597299    0.215959    0.080740    0.703264\n",
            "18   8/1/2020        0.473358    0.208015    0.087895    0.704084\n",
            "19   8/2/2020        0.555497    0.228020    0.078857    0.693156\n",
            "20   8/3/2020        0.563108    0.199992    0.073895    0.726077\n",
            "21   8/4/2020        0.544343    0.205342    0.082631    0.711982\n",
            "22   8/5/2020        0.494380    0.199889    0.090126    0.709976\n",
            "23   8/6/2020        0.342023    0.174950    0.099795    0.725201\n",
            "24   8/7/2020        0.502997    0.193653    0.087856    0.718451\n",
            "25   8/8/2020        0.660028    0.226963    0.073772    0.699267\n",
            "26   8/9/2020        0.551240    0.204284    0.087144    0.708590\n",
            "27  8/10/2020        0.486081    0.212380    0.086274    0.701367\n",
            "28  8/11/2020        0.514757    0.215922    0.085901    0.698207\n",
            "29  8/12/2020        0.434890    0.213241    0.102340    0.684429\n",
            "30  8/13/2020        0.282623    0.185129    0.111510    0.703384\n",
            "31  8/14/2020        0.523353    0.220607    0.087947    0.691493\n",
            "32  8/15/2020        0.723451    0.213253    0.061877    0.724744\n",
            "33  8/16/2020        0.696089    0.238231    0.078688    0.683204\n",
            "34  8/17/2020        0.531836    0.212013    0.089693    0.698295\n",
            "35  8/18/2020        0.650623    0.213770    0.079390    0.707009\n",
            "36  8/19/2020        0.583710    0.204678    0.095419    0.699883\n",
            "37  8/25/2020        0.530363    0.192313    0.085219    0.722500\n",
            "38  8/28/2020        0.683340    0.208932    0.068068    0.723041\n",
            "39  8/29/2020        0.645672    0.221346    0.080861    0.697673\n",
            "40  8/30/2020        0.537995    0.212633    0.083342    0.703957\n",
            "41  8/31/2020        0.517239    0.211230    0.084379    0.704305\n",
            "42   9/1/2020        0.487114    0.199045    0.087668    0.713236\n",
            "43   9/2/2020        0.343971    0.184286    0.097529    0.718184\n",
            "44   9/3/2020        0.513688    0.200143    0.086738    0.713112\n",
            "45   9/4/2020        0.509435    0.200484    0.085127    0.714414\n",
            "46   9/5/2020        0.418321    0.187579    0.094140    0.718244\n",
            "47   9/6/2020        0.463015    0.195850    0.087532    0.716525\n",
            "48   9/7/2020        0.531331    0.190888    0.076591    0.732462\n",
            "49   9/8/2020        0.377791    0.193103    0.098155    0.708794\n",
            "50   9/9/2020        0.384777    0.186742    0.093422    0.719842\n",
            "51  9/10/2020        0.455606    0.213198    0.102415    0.684380\n",
            "52  9/11/2020        0.497541    0.200315    0.087328    0.712410\n",
            "53  9/12/2020        0.540743    0.212699    0.087484    0.699826\n",
            "54  9/13/2020        0.464761    0.210690    0.093927    0.695428\n",
            "55  9/14/2020        0.531610    0.192125    0.091020    0.716835\n"
          ]
        }
      ]
    }
  ]
}